#!/usr/bin/env python3
"""
Production System Runner
Run and test the production ML pipeline system
"""

import sys
import os
import logging
from datetime import datetime

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def main():
    """Main production system runner"""
    
    print("üöÄ Production ML Pipeline System - Real Trading")
    print("=" * 60)
    
    try:
        # Test imports
        logger.info("Testing system imports...")
        
        from ml_service.tbt_data_synthesizer import TBTDataSynthesizer
        from ml_service.production_feature_engineer import ProductionFeatureEngineer
        from ml_service.production_lightgbm_trainer import ProductionLightGBMTrainer
        from ml_service.production_ml_pipeline import ProductionMLPipeline
        
        logger.info("‚úÖ All production modules imported successfully")
        
        # Initialize components
        logger.info("Initializing production components...")
        
        synthesizer = TBTDataSynthesizer()
        feature_engineer = ProductionFeatureEngineer()
        
        # Test data synthesis
        logger.info("Testing TBT data synthesis...")
        test_data = synthesizer.generate_realistic_tick_data(
            symbol="AAPL",
            duration_minutes=5,
            tick_rate_ms=10
        )
        
        logger.info(f"‚úÖ Generated {len(test_data)} ticks")
        logger.info(f"Data shape: {test_data.shape}")
        logger.info(f"Columns: {list(test_data.columns)}")
        
        # Test data validation
        logger.info("Testing data validation...")
        validation_results = synthesizer.validate_data_quality(test_data)
        
        logger.info("Data validation results:")
        for check, result in validation_results.items():
            status = "‚úÖ" if result else "‚ùå"
            logger.info(f"  {status} {check.replace('_', ' ').title()}")
        
        # Test feature engineering
        logger.info("Testing feature engineering...")
        features_df = feature_engineer.engineer_features(test_data, create_labels=True)
        
        logger.info(f"‚úÖ Engineered {len(features_df)} features")
        logger.info(f"Feature columns: {len([col for col in features_df.columns if col not in ['timestamp', 'trading_label', 'trading_label_encoded']])}")
        
        # Test feature categorization
        feature_categories = feature_engineer.categorize_features(
            [col for col in features_df.columns if col not in ['timestamp', 'trading_label', 'trading_label_encoded']]
        )
        
        logger.info("Feature categories:")
        for category, count in feature_categories.items():
            logger.info(f"  {category}: {count} features")
        
        # Test ML pipeline
        logger.info("Testing ML pipeline...")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            pipeline = ProductionMLPipeline(model_dir=temp_dir)
            
            # Test data generation
            training_data = pipeline.generate_training_data(
                symbols=['AAPL', 'MSFT'],
                duration_hours=0.1,  # 6 minutes for testing
                tick_rate_ms=10
            )
            
            logger.info(f"‚úÖ Generated training data: {len(training_data)} ticks")
            
            # Test model training (minimal for testing)
            logger.info("Testing model training...")
            training_results = pipeline.train_new_model(
                training_data,
                model_name="test_production_model",
                optimize_hyperparams=False,  # Skip optimization for speed
                n_trials=1
            )
            
            if training_results['success']:
                logger.info("‚úÖ Model training successful!")
                logger.info(f"Model saved to: {training_results['model_path']}")
                logger.info(f"Feature count: {training_results['feature_count']}")
                
                # Test prediction
                logger.info("Testing real-time prediction...")
                test_tick = pipeline.data_synthesizer.generate_realistic_tick_data(
                    "AAPL", duration_minutes=1, tick_rate_ms=100
                )
                
                prediction_result = pipeline.make_prediction(test_tick)
                
                if 'error' not in prediction_result:
                    logger.info("‚úÖ Prediction successful!")
                    logger.info(f"Prediction: {prediction_result['predictions'][0]}")
                    logger.info(f"Confidence: {prediction_result['confidence_scores'][0]:.3f}")
                    logger.info(f"Inference time: {prediction_result['inference_time_ms']:.2f}ms")
                else:
                    logger.warning(f"‚ö†Ô∏è Prediction failed: {prediction_result['error']}")
                
                # Test performance benchmarking
                logger.info("Testing performance benchmarking...")
                benchmark_results = pipeline.benchmark_performance(
                    test_tick, 
                    iterations=10  # Small number for testing
                )
                
                if 'error' not in benchmark_results:
                    logger.info("‚úÖ Performance benchmark successful!")
                    logger.info(f"Average inference time: {benchmark_results['avg_inference_time_ms']:.2f}ms")
                    logger.info(f"Throughput: {benchmark_results['throughput_ticks_per_second']:.0f} ticks/second")
                else:
                    logger.warning(f"‚ö†Ô∏è Benchmark failed: {benchmark_results['error']}")
                
            else:
                logger.warning(f"‚ö†Ô∏è Model training failed: {training_results['error']}")
        
        # System summary
        print("\n" + "=" * 60)
        print("üéâ PRODUCTION SYSTEM TESTING COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        
        print("\n‚úÖ **System Components Tested:**")
        print("  ‚Ä¢ TBT Data Synthesis Engine")
        print("  ‚Ä¢ Production Feature Engineering")
        print("  ‚Ä¢ LightGBM Model Training")
        print("  ‚Ä¢ ML Pipeline Integration")
        print("  ‚Ä¢ Real-time Inference")
        print("  ‚Ä¢ Performance Benchmarking")
        
        print("\nüöÄ **Ready for Production Deployment!**")
        print("\n**Next Steps:**")
        print("1. Start Streamlit app: python -m streamlit run app.py")
        print("2. Navigate to ML Pipeline tab")
        print("3. Generate TBT data and train models")
        print("4. Run real-time inference and performance tests")
        
        return True
        
    except ImportError as e:
        logger.error(f"‚ùå Import error: {e}")
        logger.error("Please install required dependencies: pip install -r requirements.txt")
        return False
        
    except Exception as e:
        logger.error(f"‚ùå System test failed: {e}")
        logger.error("Please check system configuration and dependencies")
        return False

if __name__ == "__main__":
    import tempfile
    
    success = main()
    sys.exit(0 if success else 1)
